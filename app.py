import streamlit as st
import requests
import folium
from streamlit_folium import st_folium
from typing import Literal
import openai
import base64
import os
from dotenv import load_dotenv

st.set_page_config(page_title="ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—è¡¨ç¤º", layout="wide", page_icon="ğŸ—¾")
st.title("ğŸ—¾ ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—è¡¨ç¤ºã‚¢ãƒ—ãƒª")
st.markdown("ä½æ‰€ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ãã®åœ°åŸŸã®ç½å®³ãƒªã‚¹ã‚¯æƒ…å ±ã‚’ç¢ºèªã§ãã¾ã™")

@st.cache_data(ttl=3600)
def get_hazard_info(lat, lon):
    """æŒ‡å®šåº§æ¨™ã®ãƒã‚¶ãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—"""
    hazard_info = {
        "flood": {"level": "ä¸æ˜", "detail": "ãƒ‡ãƒ¼ã‚¿ãªã—"},
        "landslide": {"level": "ä¸æ˜", "detail": "ãƒ‡ãƒ¼ã‚¿ãªã—"},
        "tsunami": {"level": "ä¸æ˜", "detail": "ãƒ‡ãƒ¼ã‚¿ãªã—"}
    }
    
    # æ¨™é«˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæ´¥æ³¢ãƒªã‚¹ã‚¯åˆ¤å®šç”¨ï¼‰
    try:
        elevation_url = f"https://cyberjapandata2.gsi.go.jp/general/dem/scripts/getelevation.php?lon={lon}&lat={lat}&outtype=JSON"
        elev_response = requests.get(elevation_url)
        elev_data = elev_response.json()
        
        if "elevation" in elev_data:
            elevation = float(elev_data["elevation"])
            
            # ç°¡æ˜“çš„ãªæ´¥æ³¢ãƒªã‚¹ã‚¯åˆ¤å®š
            if elevation < 5:
                hazard_info["tsunami"]["level"] = "é«˜ã„"
                hazard_info["tsunami"]["detail"] = f"æ¨™é«˜ {elevation:.1f}mï¼ˆæ²¿å²¸ä½åœ°ï¼‰"
            elif elevation < 10:
                hazard_info["tsunami"]["level"] = "ä¸­ç¨‹åº¦"
                hazard_info["tsunami"]["detail"] = f"æ¨™é«˜ {elevation:.1f}m"
            else:
                hazard_info["tsunami"]["level"] = "ä½ã„"
                hazard_info["tsunami"]["detail"] = f"æ¨™é«˜ {elevation:.1f}m"
    except:
        pass
    
    # æ´ªæ°´ãƒªã‚¹ã‚¯ã®ç°¡æ˜“åˆ¤å®šï¼ˆæ²³å·ã‹ã‚‰ã®è·é›¢ç­‰ã§åˆ¤å®šã™ã‚‹å®Ÿè£…ãŒå¿…è¦ï¼‰
    # ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã§ã¯åœ°åŸŸã«ã‚ˆã£ã¦ä»®ã®å€¤ã‚’è¨­å®š
    if lat > 35.6 and lat < 35.7 and lon > 139.7 and lon < 139.8:  # æ±äº¬éƒ½å¿ƒéƒ¨
        hazard_info["flood"]["level"] = "ä¸­ç¨‹åº¦"
        hazard_info["flood"]["detail"] = "æ²³å·æ°¾æ¿«æƒ³å®šåŒºåŸŸ"
    
    return hazard_info

def call_llm_api_with_image(image_file, api_key):
    """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥LLM APIã«é€ä¿¡ã—ã¦çµæœã‚’å–å¾—"""
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    try:
        openai.api_key = api_key
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        image_file.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
        image_base64 = base64.b64encode(image_file.read()).decode('utf-8')
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’å–å¾—
        file_type = image_file.type if hasattr(image_file, 'type') else 'image/png'
        
        full_prompt = """
{
 'request': 'Extract the following information from the provided PDF document into a JSON format:',
 'fields': {
  'document_type': 'The type of the document',
  'sample_document': "Boolean indicating if it's a sample document ()",
  'date_of_issue': 'The issue date of the document',
  'issuing_office': 'The office that issued the document',
  'registrar': 'The name of the registrar',
  'management_number': 'The management number',
  'disclaimer_underline': 'The disclaimer regarding underlined items',
  'land_information': {
   'real_estate_number': 'ä¸å‹•ç”£ç•ªå·',
   'location': 'æ‰€åœ¨',
   'lot_number': 'åœ°ç•ª',
   'land_category': 'åœ°ç›®',
   'land_area_sqm': 'åœ°ç© (mÂ²)',
   'cause_and_date': {
    'cause': 'åŸå› ',
    'registration_date': 'ç™»è¨˜ã®æ—¥ä»˜'
   },
   'owner': {
    'address': 'æ‰€æœ‰è€…ä½æ‰€',
    'name': 'æ‰€æœ‰è€…å'
   }
  },
  'rights_section_A_ownership': [
   {
    'sequence_number': 'é †ä½ç•ªå·',
    'purpose_of_registration': 'ç™»è¨˜ã®ç›®çš„',
    'reception_date_and_number': 'å—ä»˜å¹´æœˆæ—¥ãƒ»å—ä»˜ç•ªå·',
    'rights_holder_and_other_matters': {
     'owner_address': 'æ‰€æœ‰è€…ä½æ‰€',
     'owner_name': 'æ‰€æœ‰è€…å',
     'cause': 'åŸå› ',
     'is_erased': 'æŠ¹æ¶ˆäº‹é …ã§ã‚ã‚‹ã‹ (boolean, ä¸‹ç·šãŒã‚ã‚Œã°true)'
    }
   }
  ],
  'rights_section_B_other_rights': [
   {
    'sequence_number': 'é †ä½ç•ªå·',
    'purpose_of_registration': 'ç™»è¨˜ã®ç›®çš„',
    'reception_date_and_number': 'å—ä»˜å¹´æœˆæ—¥ãƒ»å—ä»˜ç•ªå·',
    'rights_holder_and_other_matters': {
     'cause': 'åŸå› ',
     'debt_amount_yen': 'å‚µæ¨©é¡ (å††)',
     'interest_rate_annual_percent': 'åˆ©æ¯ (å¹´ç‡%)',
     'damages_rate_annual_percent': 'æå®³é‡‘ (å¹´ç‡%)',
     'debtor': {
      'address': 'å‚µå‹™è€…ä½æ‰€',
      'name': 'å‚µå‹™è€…å'
     },
     'mortgage_holder': {
      'address': 'æŠµå½“æ¨©è€…ä½æ‰€',
      'name': 'æŠµå½“æ¨©è€…å',
      'branch_name': 'å–æ‰±åº—'
     },
     'joint_collateral_catalog_number': 'å…±åŒæ‹…ä¿ç›®éŒ²ç•ªå·',
     'is_erased': 'æŠ¹æ¶ˆäº‹é …ã§ã‚ã‚‹ã‹ (boolean, ä¸‹ç·šãŒã‚ã‚Œã°true)'
    }
   }
  ],
  'joint_collateral_catalog': {
   'catalog_number': 'å…±åŒæ‹…ä¿ç›®éŒ²ã®ç•ªå·',
   'prepared_date': 'èª¿è£½æ—¥',
   'items': [
    {
     'number': 'ç•ªå·',
     'description_of_right': 'æ‹…ä¿ã®ç›®çš„ã§ã‚ã‚‹æ¨©åˆ©ã®è¡¨ç¤º',
     'sequence_number': 'é †ä½ç•ªå·',
     'is_erased': 'æŠ¹æ¶ˆäº‹é …ã§ã‚ã‚‹ã‹ (boolean, ä¸‹ç·šãŒã‚ã‚Œã°true)'
    }
   ]
  }
 }
}
"""
        
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ—¥æœ¬ã®ä½æ‰€æƒ…å ±ã®æŠ½å‡ºã¨åˆ†æã‚’å¾—æ„ã¨ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿å–ã‚Šã€åˆ†æã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": full_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{file_type};base64,{image_base64}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=1500,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def extract_data_from_response(response_text):
    """LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ä½æ‰€ã¨åœŸåœ°æƒ…å ±ã‚’æŠ½å‡º"""
    addresses = []
    land_info = None
    
    try:
        # JSONã¨ã—ã¦è§£æã‚’è©¦ã¿ã‚‹
        import json
        data = json.loads(response_text)
        
        # land_informationå…¨ä½“ã‚’ä¿å­˜
        if 'land_information' in data:
            land_info = data['land_information']
            
            # åœŸåœ°ã®æ‰€åœ¨åœ°ã‚’æŠ½å‡º
            if 'location' in land_info:
                location = land_info['location']
                if location and location not in addresses:
                    addresses.append(location)
            
            # æ‰€æœ‰è€…ä½æ‰€ã‚’æŠ½å‡º
            if 'owner' in land_info and 'address' in land_info['owner']:
                owner_address = land_info['owner']['address']
                if owner_address and owner_address not in addresses:
                    addresses.append(owner_address)
        
        # æ¨©åˆ©éƒ¨Aï¼ˆæ‰€æœ‰æ¨©ï¼‰ã‹ã‚‰ä½æ‰€ã‚’æŠ½å‡º
        if 'rights_section_A_ownership' in data:
            for item in data['rights_section_A_ownership']:
                if 'rights_holder_and_other_matters' in item and 'owner_address' in item['rights_holder_and_other_matters']:
                    addr = item['rights_holder_and_other_matters']['owner_address']
                    if addr and addr not in addresses:
                        addresses.append(addr)
        
        # æ¨©åˆ©éƒ¨Bï¼ˆãã®ä»–ã®æ¨©åˆ©ï¼‰ã‹ã‚‰ä½æ‰€ã‚’æŠ½å‡º
        if 'rights_section_B_other_rights' in data:
            for item in data['rights_section_B_other_rights']:
                if 'rights_holder_and_other_matters' in item:
                    matters = item['rights_holder_and_other_matters']
                    # å‚µå‹™è€…ä½æ‰€
                    if 'debtor' in matters and 'address' in matters['debtor']:
                        addr = matters['debtor']['address']
                        if addr and addr not in addresses:
                            addresses.append(addr)
                    # æŠµå½“æ¨©è€…ä½æ‰€
                    if 'mortgage_holder' in matters and 'address' in matters['mortgage_holder']:
                        addr = matters['mortgage_holder']['address']
                        if addr and addr not in addresses:
                            addresses.append(addr)
    
    except json.JSONDecodeError:
        # JSONè§£æã«å¤±æ•—ã—ãŸå ´åˆã¯ã€å¾“æ¥ã®æ–¹æ³•ã§æŠ½å‡ºã‚’è©¦ã¿ã‚‹
        lines = response_text.split('\n')
        for line in lines:
            line = line.strip()
            # æ—¥æœ¬ã®ä½æ‰€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™ï¼ˆéƒ½é“åºœçœŒã‹ã‚‰å§‹ã¾ã‚‹ï¼‰
            if any(pref in line for pref in ['æ±äº¬éƒ½', 'å¤§é˜ªåºœ', 'äº¬éƒ½åºœ', 'åŒ—æµ·é“'] + [f'{p}çœŒ' for p in ['é’æ£®', 'å²©æ‰‹', 'å®®åŸ', 'ç§‹ç”°', 'å±±å½¢', 'ç¦å³¶', 'èŒ¨åŸ', 'æ ƒæœ¨', 'ç¾¤é¦¬', 'åŸ¼ç‰', 'åƒè‘‰', 'ç¥å¥ˆå·', 'æ–°æ½Ÿ', 'å¯Œå±±', 'çŸ³å·', 'ç¦äº•', 'å±±æ¢¨', 'é•·é‡', 'å²é˜œ', 'é™å²¡', 'æ„›çŸ¥', 'ä¸‰é‡', 'æ»‹è³€', 'å…µåº«', 'å¥ˆè‰¯', 'å’Œæ­Œå±±', 'é³¥å–', 'å³¶æ ¹', 'å²¡å±±', 'åºƒå³¶', 'å±±å£', 'å¾³å³¶', 'é¦™å·', 'æ„›åª›', 'é«˜çŸ¥', 'ç¦å²¡', 'ä½è³€', 'é•·å´', 'ç†Šæœ¬', 'å¤§åˆ†', 'å®®å´', 'é¹¿å…å³¶', 'æ²–ç¸„']]):
                # ä½æ‰€ã¨ã—ã¦æŠ½å‡º
                if line not in addresses and len(line) > 5:  # æœ€ä½é™ã®é•·ã•ãƒã‚§ãƒƒã‚¯
                    addresses.append(line)
    
    return addresses, land_info

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'llm_response' not in st.session_state:
    st.session_state.llm_response = None
if 'extracted_addresses' not in st.session_state:
    st.session_state.extracted_addresses = []
if 'land_information' not in st.session_state:
    st.session_state.land_information = None

# ã‚µãƒ³ãƒ—ãƒ«ä½æ‰€
sample_addresses = {
    "æ±äº¬éƒ½æ±Ÿæ±åŒºè±Šæ´²3-3-3": "æ²³å·ã«è¿‘ã„åœ°åŸŸ",
    "æ±äº¬éƒ½æ¸¯åŒºæµ·å²¸1-1-1": "æ²¿å²¸éƒ¨ã®åœ°åŸŸ",
    "æ±äº¬éƒ½ä¸–ç”°è°·åŒºæˆåŸ6-1-1": "å†…é™¸ã®ä½å®…åœ°",
    "ç¥å¥ˆå·çœŒéŒå€‰å¸‚ç”±æ¯”ã‚¬æµœ2-1-1": "æµ·å²¸æ²¿ã„ã®åœ°åŸŸ",
    "æ±äº¬éƒ½å…«ç‹å­å¸‚é«˜å°¾ç”º1-1": "å±±é–“éƒ¨ã®åœ°åŸŸ"
}

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'search_address' not in st.session_state:
    st.session_state.search_address = None

# ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
st.markdown("---")
st.subheader("ğŸ–¼ï¸ ç”»åƒåˆ†ææ©Ÿèƒ½")
st.markdown("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€AIåˆ†æã«ã‚ˆã‚Šä½æ‰€æƒ…å ±ã‚’æŠ½å‡ºã—ã¾ã™")


# ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
with st.container():
    uploaded_file = st.file_uploader(
        "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["png", "jpg", "jpeg"],
        help="åˆ†æã—ãŸã„ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )

# åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
if uploaded_file:
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    
    if api_key:
        if st.button("ğŸ¤– AIåˆ†æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
            with st.spinner("ç”»åƒã‚’åˆ†æä¸­..."):
                # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥LLM APIã«é€ä¿¡
                llm_response = call_llm_api_with_image(uploaded_file, api_key)
                
                if llm_response:
                    st.session_state.llm_response = llm_response
                    addresses, land_info = extract_data_from_response(llm_response)
                    st.session_state.extracted_addresses = addresses
                    st.session_state.land_information = land_info
    else:
        st.error("âš ï¸ OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

# LLMåˆ†æçµæœã®è¡¨ç¤º
if st.session_state.llm_response:
    st.markdown("---")
    st.subheader("ğŸ¤– AIåˆ†æçµæœ")
    
    # åˆ†æçµæœã‚’è¡¨ç¤º
    with st.expander("ğŸ“‹ å®Œå…¨ãªåˆ†æçµæœ", expanded=False):
        st.markdown(st.session_state.llm_response)
    
    # åœŸåœ°æƒ…å ±ã‚’è¡¨ç¤º
    if st.session_state.land_information:
        st.markdown("### ğŸ“„ åœŸåœ°æƒ…å ±")
        
        land_info = st.session_state.land_information
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**åŸºæœ¬æƒ…å ±**")
            if 'real_estate_number' in land_info and land_info['real_estate_number']:
                st.write(f"â€¢ ä¸å‹•ç”£ç•ªå·: {land_info['real_estate_number']}")
            
            # æ‰€åœ¨åœ°ã‚’ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ã«ã™ã‚‹
            if 'location' in land_info and land_info['location']:
                location_col1, location_col2 = st.columns([1, 3])
                with location_col1:
                    st.write("â€¢ æ‰€åœ¨:")
                with location_col2:
                    if st.button(
                        f"ğŸ“ {land_info['location']}", 
                        key="land_location_btn",
                        use_container_width=True,
                        help="ã‚¯ãƒªãƒƒã‚¯ã—ã¦ä½æ‰€ã¨ã—ã¦ä½¿ç”¨"
                    ):
                        st.session_state.search_address = land_info['location']
                        st.session_state.selected_extracted = land_info['location']
                        st.success(f"ä½æ‰€ã‚’è¨­å®šã—ã¾ã—ãŸ: {land_info['location']}")
                        st.rerun()
            
            if 'lot_number' in land_info and land_info['lot_number']:
                st.write(f"â€¢ åœ°ç•ª: {land_info['lot_number']}")
            
            # æ‰€åœ¨åœ°ã¨åœ°ç•ªã‚’çµ„ã¿åˆã‚ã›ãŸå®Œå…¨ãªä½æ‰€ã‚’æä¾›
            if 'location' in land_info and land_info['location'] and 'lot_number' in land_info and land_info['lot_number']:
                full_address = f"{land_info['location']}{land_info['lot_number']}"
                if st.button(
                    f"ğŸ“ {full_address} (æ‰€åœ¨+åœ°ç•ª)", 
                    key="full_address_btn",
                    use_container_width=True,
                    help="æ‰€åœ¨åœ°ã¨åœ°ç•ªã‚’çµ„ã¿åˆã‚ã›ãŸä½æ‰€ã‚’ä½¿ç”¨"
                ):
                    st.session_state.search_address = full_address
                    st.session_state.selected_extracted = full_address
                    st.success(f"ä½æ‰€ã‚’è¨­å®šã—ã¾ã—ãŸ: {full_address}")
                    st.rerun()
            if 'land_category' in land_info and land_info['land_category']:
                st.write(f"â€¢ åœ°ç›®: {land_info['land_category']}")
            if 'land_area_sqm' in land_info and land_info['land_area_sqm']:
                st.write(f"â€¢ åœ°ç©: {land_info['land_area_sqm']}")
        
        with col2:
            st.markdown("**æ‰€æœ‰è€…æƒ…å ±**")
            if 'owner' in land_info:
                if 'name' in land_info['owner'] and land_info['owner']['name']:
                    st.write(f"â€¢ æ‰€æœ‰è€…å: {land_info['owner']['name']}")
                
                # æ‰€æœ‰è€…ä½æ‰€ã‚’ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ã«ã™ã‚‹
                if 'address' in land_info['owner'] and land_info['owner']['address']:
                    owner_col1, owner_col2 = st.columns([1, 3])
                    with owner_col1:
                        st.write("â€¢ æ‰€æœ‰è€…ä½æ‰€:")
                    with owner_col2:
                        if st.button(
                            f"ğŸ“ {land_info['owner']['address']}", 
                            key="owner_address_btn",
                            use_container_width=True,
                            help="ã‚¯ãƒªãƒƒã‚¯ã—ã¦ä½æ‰€ã¨ã—ã¦ä½¿ç”¨"
                        ):
                            st.session_state.search_address = land_info['owner']['address']
                            st.session_state.selected_extracted = land_info['owner']['address']
                            st.success(f"ä½æ‰€ã‚’è¨­å®šã—ã¾ã—ãŸ: {land_info['owner']['address']}")
                            st.rerun()
            
            if 'cause_and_date' in land_info:
                st.markdown("**åŸå› ãƒ»æ—¥ä»˜**")
                if 'cause' in land_info['cause_and_date'] and land_info['cause_and_date']['cause']:
                    st.write(f"â€¢ åŸå› : {land_info['cause_and_date']['cause']}")
                if 'registration_date' in land_info['cause_and_date'] and land_info['cause_and_date']['registration_date']:
                    st.write(f"â€¢ ç™»è¨˜æ—¥ä»˜: {land_info['cause_and_date']['registration_date']}")
    
    # æŠ½å‡ºã•ã‚ŒãŸä½æ‰€ã‚’è¡¨ç¤º
    if st.session_state.extracted_addresses:
        st.markdown("### ğŸ“ æŠ½å‡ºã•ã‚ŒãŸä½æ‰€")
        
        # ä½æ‰€ã‚’ãƒœã‚¿ãƒ³ã§è¡¨ç¤ºï¼ˆã‚¯ãƒªãƒƒã‚¯ã§ã‚«ã‚¹ã‚¿ãƒ ä½æ‰€æ¬„ã«å…¥åŠ›ï¼‰
        address_cols = st.columns(min(3, len(st.session_state.extracted_addresses)))
        for idx, address in enumerate(st.session_state.extracted_addresses):
            col_idx = idx % len(address_cols)
            with address_cols[col_idx]:
                if st.button(
                    f"ğŸ“ {address}",
                    key=f"extracted_address_{idx}",
                    use_container_width=True,
                    help="ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚«ã‚¹ã‚¿ãƒ ä½æ‰€æ¬„ã«å…¥åŠ›"
                ):
                    st.session_state.search_address = address
                    st.session_state.selected_extracted = address
                    st.success(f"ä½æ‰€ã‚’è¨­å®šã—ã¾ã—ãŸ: {address}")
                    st.rerun()
    
    # çµæœã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãƒœã‚¿ãƒ³
    if st.button("ğŸ—‘ï¸ åˆ†æçµæœã‚’ã‚¯ãƒªã‚¢", type="secondary"):
        st.session_state.llm_response = None
        st.session_state.extracted_addresses = []
        st.session_state.land_information = None
        st.rerun()

# UIã‚³ãƒ³ãƒ†ãƒŠ
with st.container():
    st.subheader("ğŸ“ ä½æ‰€ã‚’å…¥åŠ›")
    
    # ã‚«ã‚¹ã‚¿ãƒ ä½æ‰€å…¥åŠ›
    with st.form(key='address_form'):
        col1, col2 = st.columns([4, 1])
        with col1:
            # æŠ½å‡ºã•ã‚ŒãŸä½æ‰€ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ã—ã¦è¨­å®š
            default_address = ""
            if hasattr(st.session_state, 'selected_extracted') and st.session_state.selected_extracted:
                default_address = st.session_state.selected_extracted
                # ä¸€åº¦ä½¿ã£ãŸã‚‰ã‚¯ãƒªã‚¢
                st.session_state.selected_extracted = None
            
            custom_address = st.text_input(
                "ä½æ‰€",
                value=default_address,
                placeholder="ä¾‹: æ±äº¬éƒ½åƒä»£ç”°åŒºä¸¸ã®å†…1-1-1",
                label_visibility="collapsed"
            )
        with col2:
            search_button = st.form_submit_button("ğŸ” æ¤œç´¢", type="primary", use_container_width=True)
    
    # ã‚µãƒ³ãƒ—ãƒ«ä½æ‰€é¸æŠ
    with st.expander("ğŸ’¡ ã‚µãƒ³ãƒ—ãƒ«ä½æ‰€ã‹ã‚‰é¸æŠ", expanded=False):
        sample_cols = st.columns(2)
        for idx, (address, description) in enumerate(sample_addresses.items()):
            col = sample_cols[idx % 2]
            with col:
                if st.button(f"{address}\n({description})", key=f"sample_{idx}", use_container_width=True):
                    st.session_state.search_address = address
                    st.session_state.selected_sample = address

# æ¤œç´¢å®Ÿè¡Œã®åˆ¤å®š
address = None

# ã‚«ã‚¹ã‚¿ãƒ ä½æ‰€ã®æ¤œç´¢ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆ
if search_button and custom_address:
    st.session_state.search_address = custom_address
    address = custom_address

# å‰å›ã®æ¤œç´¢çµæœã‚’ç¶­æŒã¾ãŸã¯ã‚µãƒ³ãƒ—ãƒ«é¸æŠ
elif st.session_state.search_address:
    address = st.session_state.search_address

# ä½æ‰€æƒ…å ±ã®è¡¨ç¤º
if address and address in sample_addresses:
    st.info(f"ğŸ“ {address} - {sample_addresses[address]}")

if address:
    # ä½æ‰€ã‹ã‚‰ç·¯åº¦çµŒåº¦ã‚’å–å¾—ï¼ˆå›½åœŸåœ°ç†é™¢ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°APIï¼‰
    geocoding_url = f"https://msearch.gsi.go.jp/address-search/AddressSearch?q={address}"

    try:
        response = requests.get(geocoding_url)
        data = response.json()

        if data:
            # æœ€åˆã®æ¤œç´¢çµæœã‚’ä½¿ç”¨
            first_result = data[0]
            lat = first_result["geometry"]["coordinates"][1]
            lon = first_result["geometry"]["coordinates"][0]

            with st.container():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.success(f"ğŸ“ {first_result['properties']['title']}")
                with col2:
                    st.metric("åº§æ¨™", f"{lat:.4f}, {lon:.4f}", label_visibility="collapsed")

            # åœ°å›³ã‚’ä½œæˆ
            m = folium.Map(location=[lat, lon], zoom_start=15)

            # å…¥åŠ›ã—ãŸä½æ‰€ã®ä½ç½®ã«ãƒãƒ¼ã‚«ãƒ¼ã‚’é…ç½®
            folium.Marker(
                [lat, lon],
                popup=address,
                tooltip=address,
                icon=folium.Icon(color='red', icon='home')
            ).add_to(m)

            # ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚¿ã‚¤ãƒ«ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’è¿½åŠ 
            # æ´ªæ°´æµ¸æ°´æƒ³å®šåŒºåŸŸï¼ˆæƒ³å®šæœ€å¤§è¦æ¨¡ï¼‰
            folium.TileLayer(
                tiles='https://disaportaldata.gsi.go.jp/raster/01_flood_l2_shinsuishin_data/{z}/{x}/{y}.png',
                attr='å›½åœŸåœ°ç†é™¢',
                name='æ´ªæ°´æµ¸æ°´æƒ³å®šåŒºåŸŸ',
                overlay=True,
                control=True,
                opacity=0.6
            ).add_to(m)

            # æ´¥æ³¢æµ¸æ°´æƒ³å®š
            folium.TileLayer(
                tiles='https://disaportaldata.gsi.go.jp/raster/04_tsunami_newlegend_data/{z}/{x}/{y}.png',
                attr='å›½åœŸåœ°ç†é™¢',
                name='æ´¥æ³¢æµ¸æ°´æƒ³å®š',
                overlay=True,
                control=True,
                opacity=0.6
            ).add_to(m)

            # åœŸç ‚ç½å®³è­¦æˆ’åŒºåŸŸ
            folium.TileLayer(
                tiles='https://disaportaldata.gsi.go.jp/raster/05_dosekiryukeikaikuiki/{z}/{x}/{y}.png',
                attr='å›½åœŸåœ°ç†é™¢',
                name='åœŸç ‚ç½å®³è­¦æˆ’åŒºåŸŸ',
                overlay=True,
                control=True,
                opacity=0.6
            ).add_to(m)

            # ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã‚’è¿½åŠ 
            folium.LayerControl().add_to(m)

            # åœ°å›³ã¨ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—èª¬æ˜ã‚’æ¨ªä¸¦ã³ã«
            st.markdown("---")
            st.subheader("ğŸ—ºï¸ ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—")
            
            map_col, info_col = st.columns([3, 1])
            
            with map_col:
                # åœ°å›³ã‚’è¡¨ç¤º
                st_folium(m, width=700, height=500, returned_objects=[])
            
            with info_col:
                st.markdown("### å‡¡ä¾‹")
                st.markdown("""
                ğŸ”µ **æ´ªæ°´æµ¸æ°´æƒ³å®šåŒºåŸŸ**  
                æ²³å·æ°¾æ¿«æ™‚ã®æµ¸æ°´æ·±
                
                ğŸŒŠ **æ´¥æ³¢æµ¸æ°´æƒ³å®š**  
                æ´¥æ³¢ã«ã‚ˆã‚‹æµ¸æ°´æ·±
                
                ğŸŸ¡ **åœŸç ‚ç½å®³è­¦æˆ’åŒºåŸŸ**  
                åœŸç ‚ç½å®³ã®å±é™ºæ€§
                
                ---
                
                ğŸ’¡ **æ“ä½œæ–¹æ³•**
                - å³ä¸Šã®ãƒœã‚¿ãƒ³ã§ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ‡æ›¿
                - ãƒã‚¦ã‚¹ã§åœ°å›³ã®ç§»å‹•ãƒ»æ‹¡å¤§ç¸®å°
                """)
                
                st.warning("åœ°åŸŸã«ã‚ˆã£ã¦ã¯ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆãŒã‚ã‚Šã¾ã™", icon="âš ï¸")

            # å±é™ºåº¦åˆ¤å®š
            st.markdown("---")
            st.subheader("ğŸ“Š å±é™ºåº¦åˆ¤å®š")

            # å®Ÿéš›ã®ãƒã‚¶ãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—
            hazard_info = get_hazard_info(lat, lon)
            
            # ãƒªã‚¹ã‚¯è©•ä¾¡ã‚’3åˆ—ã§è¡¨ç¤º
            risk_cols = st.columns(3)
            
            # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸè‰²ã¨ã‚¢ã‚¤ã‚³ãƒ³ã‚’è¨­å®š
            def get_risk_color(level) -> Literal["normal", "inverse", "off"]:
                if level == "é«˜ã„":
                    return "inverse"
                elif level == "ä¸­ç¨‹åº¦":
                    return "normal"
                else:
                    return "off"
            
            def get_risk_icon(level) -> str:
                if level == "é«˜ã„":
                    return "ğŸ”´"
                elif level == "ä¸­ç¨‹åº¦":
                    return "ğŸŸ¡"
                else:
                    return "ğŸŸ¢"
            
            with risk_cols[0]:
                icon = get_risk_icon(hazard_info["flood"]["level"])
                color = get_risk_color(hazard_info["flood"]["level"])
                st.metric(
                    label=f"{icon} æ´ªæ°´ãƒªã‚¹ã‚¯",
                    value=hazard_info["flood"]["level"],
                    delta=hazard_info["flood"]["detail"],
                    delta_color=color
                )
            
            with risk_cols[1]:
                icon = get_risk_icon(hazard_info["landslide"]["level"])
                color = get_risk_color(hazard_info["landslide"]["level"])
                st.metric(
                    label=f"{icon} åœŸç ‚ç½å®³ãƒªã‚¹ã‚¯",
                    value=hazard_info["landslide"]["level"],
                    delta=hazard_info["landslide"]["detail"],
                    delta_color=color
                )
            
            with risk_cols[2]:
                icon = get_risk_icon(hazard_info["tsunami"]["level"])
                color = get_risk_color(hazard_info["tsunami"]["level"])
                st.metric(
                    label=f"{icon} æ´¥æ³¢ãƒªã‚¹ã‚¯",
                    value=hazard_info["tsunami"]["level"],
                    delta=hazard_info["tsunami"]["detail"],
                    delta_color=color
                )
            
            # æ³¨æ„äº‹é …
            with st.expander("âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …", expanded=False):
                st.warning("""
                - ã“ã®è©•ä¾¡ã¯æ¨™é«˜ãƒ‡ãƒ¼ã‚¿ç­‰ã‚’åŸºã«ã—ãŸç°¡æ˜“çš„ãªåˆ¤å®šã§ã™
                - æ­£ç¢ºãªæƒ…å ±ã¯å„è‡ªæ²»ä½“ã®å…¬å¼ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’ã”ç¢ºèªãã ã•ã„
                - å®Ÿéš›ã®ç½å®³ãƒªã‚¹ã‚¯ã¯åœ°å½¢ã€å»ºç‰©ã€å­£ç¯€ã€æ°—è±¡æ¡ä»¶ã«ã‚ˆã‚Šå¤‰å‹•ã—ã¾ã™
                - é¿é›£å ´æ‰€ã‚„é¿é›£çµŒè·¯ã‚‚ä½µã›ã¦ç¢ºèªã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™
                - æœ€æ–°ã®é˜²ç½æƒ…å ±ã¯è‡ªæ²»ä½“ã®é˜²ç½ãƒšãƒ¼ã‚¸ã§ã”ç¢ºèªãã ã•ã„
                """)

        else:
            st.error("ä½æ‰€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ä½æ‰€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")