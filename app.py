import streamlit as st
import requests
import folium
from streamlit_folium import st_folium
from typing import Literal
from openai import OpenAI
import base64
import os

st.set_page_config(page_title="ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—è¡¨ç¤º", layout="wide", page_icon="ğŸ—¾")
st.title("ğŸ—¾ ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—è¡¨ç¤ºã‚¢ãƒ—ãƒª")
st.markdown("ä½æ‰€ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ãã®åœ°åŸŸã®ç½å®³ãƒªã‚¹ã‚¯æƒ…å ±ã‚’ç¢ºèªã§ãã¾ã™")

@st.cache_data(ttl=3600)
def get_hazard_info(lat, lon):
    """æŒ‡å®šåº§æ¨™ã®ãƒã‚¶ãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—"""
    hazard_info = {
        "flood": {"level": "ä¸æ˜", "detail": "ãƒ‡ãƒ¼ã‚¿ãªã—"},
        "landslide": {"level": "ä¸æ˜", "detail": "ãƒ‡ãƒ¼ã‚¿ãªã—"},
        "tsunami": {"level": "ä¸æ˜", "detail": "ãƒ‡ãƒ¼ã‚¿ãªã—"}
    }
    
    # æ¨™é«˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæ´¥æ³¢ãƒªã‚¹ã‚¯åˆ¤å®šç”¨ï¼‰
    try:
        elevation_url = f"https://cyberjapandata2.gsi.go.jp/general/dem/scripts/getelevation.php?lon={lon}&lat={lat}&outtype=JSON"
        elev_response = requests.get(elevation_url)
        elev_data = elev_response.json()
        
        if "elevation" in elev_data:
            elevation = float(elev_data["elevation"])
            
            # ç°¡æ˜“çš„ãªæ´¥æ³¢ãƒªã‚¹ã‚¯åˆ¤å®š
            if elevation < 5:
                hazard_info["tsunami"]["level"] = "é«˜ã„"
                hazard_info["tsunami"]["detail"] = f"æ¨™é«˜ {elevation:.1f}mï¼ˆæ²¿å²¸ä½åœ°ï¼‰"
            elif elevation < 10:
                hazard_info["tsunami"]["level"] = "ä¸­ç¨‹åº¦"
                hazard_info["tsunami"]["detail"] = f"æ¨™é«˜ {elevation:.1f}m"
            else:
                hazard_info["tsunami"]["level"] = "ä½ã„"
                hazard_info["tsunami"]["detail"] = f"æ¨™é«˜ {elevation:.1f}m"
    except:
        pass
    
    # æ´ªæ°´ãƒªã‚¹ã‚¯ã®ç°¡æ˜“åˆ¤å®šï¼ˆæ²³å·ã‹ã‚‰ã®è·é›¢ç­‰ã§åˆ¤å®šã™ã‚‹å®Ÿè£…ãŒå¿…è¦ï¼‰
    # ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã§ã¯åœ°åŸŸã«ã‚ˆã£ã¦ä»®ã®å€¤ã‚’è¨­å®š
    if lat > 35.6 and lat < 35.7 and lon > 139.7 and lon < 139.8:  # æ±äº¬éƒ½å¿ƒéƒ¨
        hazard_info["flood"]["level"] = "ä¸­ç¨‹åº¦"
        hazard_info["flood"]["detail"] = "æ²³å·æ°¾æ¿«æƒ³å®šåŒºåŸŸ"
    
    return hazard_info

def check_proxy_settings():
    proxy_keys = [
        "http_proxy", "https_proxy",
        "HTTP_PROXY", "HTTPS_PROXY"
    ]
    
    found = False
    for key in proxy_keys:
        value = os.environ.get(key)
        if value:
            st.write(f"âš ï¸ `{key}` ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™: `{value}`")
            found = True
    
    if not found:
        st.success("ãƒ—ãƒ­ã‚­ã‚·ç’°å¢ƒå¤‰æ•°ã¯è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

check_proxy_settings()

def call_llm_api_with_image(image_file, prompt, api_key):
    """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥LLM APIã«é€ä¿¡ã—ã¦çµæœã‚’å–å¾—"""
    check_proxy_settings()
    try:
        client = OpenAI(api_key=api_key)
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        image_file.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
        image_base64 = base64.b64encode(image_file.read()).decode('utf-8')
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚’å–å¾—
        file_type = image_file.type if hasattr(image_file, 'type') else 'image/png'
        
        full_prompt = f"""
ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
ç‰¹ã«ä½æ‰€æƒ…å ±ã«æ³¨ç›®ã—ã¦åˆ†æã—ã¦ãã ã•ã„ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}

ä½æ‰€æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
ã€ä½æ‰€ä¸€è¦§ã€‘
- ä½æ‰€1
- ä½æ‰€2
- ...

ãã®ä»–ã®åˆ†æçµæœã‚‚å«ã‚ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ—¥æœ¬ã®ä½æ‰€æƒ…å ±ã®æŠ½å‡ºã¨åˆ†æã‚’å¾—æ„ã¨ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿å–ã‚Šã€åˆ†æã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚"},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": full_prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:{file_type};base64,{image_base64}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=1500,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def extract_addresses_from_response(response_text):
    """LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ä½æ‰€ã‚’æŠ½å‡º"""
    addresses = []
    lines = response_text.split('\n')
    in_address_section = False
    
    for line in lines:
        line = line.strip()
        if 'ã€ä½æ‰€ä¸€è¦§ã€‘' in line or 'ä½æ‰€ä¸€è¦§' in line:
            in_address_section = True
            continue
        elif line.startswith('ã€') and line.endswith('ã€‘'):
            in_address_section = False
            continue
        elif in_address_section and line.startswith('- '):
            address = line[2:].strip()
            if address:
                addresses.append(address)
    
    return addresses

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'llm_response' not in st.session_state:
    st.session_state.llm_response = None
if 'extracted_addresses' not in st.session_state:
    st.session_state.extracted_addresses = []

# ã‚µãƒ³ãƒ—ãƒ«ä½æ‰€
sample_addresses = {
    "æ±äº¬éƒ½æ±Ÿæ±åŒºè±Šæ´²3-3-3": "æ²³å·ã«è¿‘ã„åœ°åŸŸ",
    "æ±äº¬éƒ½æ¸¯åŒºæµ·å²¸1-1-1": "æ²¿å²¸éƒ¨ã®åœ°åŸŸ",
    "æ±äº¬éƒ½ä¸–ç”°è°·åŒºæˆåŸ6-1-1": "å†…é™¸ã®ä½å®…åœ°",
    "ç¥å¥ˆå·çœŒéŒå€‰å¸‚ç”±æ¯”ã‚¬æµœ2-1-1": "æµ·å²¸æ²¿ã„ã®åœ°åŸŸ",
    "æ±äº¬éƒ½å…«ç‹å­å¸‚é«˜å°¾ç”º1-1": "å±±é–“éƒ¨ã®åœ°åŸŸ"
}

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'search_address' not in st.session_state:
    st.session_state.search_address = None

# ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
st.markdown("---")
st.subheader("ğŸ–¼ï¸ ç”»åƒåˆ†ææ©Ÿèƒ½")
st.markdown("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€AIåˆ†æã«ã‚ˆã‚Šä½æ‰€æƒ…å ±ã‚’æŠ½å‡ºã—ã¾ã™")

with st.container():
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # APIã‚­ãƒ¼å…¥åŠ›
        api_key = st.text_input(
            "OpenAI APIã‚­ãƒ¼",
            type="password",
            placeholder="sk-...",
            help="OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
    
    with col2:
        st.markdown("")  # ã‚¹ãƒšãƒ¼ã‚¹èª¿æ•´

# ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ›
with st.container():
    col1, col2 = st.columns([2, 2])
    
    with col1:
        uploaded_file = st.file_uploader(
            "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["png", "jpg", "jpeg"],
            help="åˆ†æã—ãŸã„ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
    
    with col2:
        prompt = st.text_area(
            "åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            placeholder="ä¾‹: ã“ã®æ–‡æ›¸ã‹ã‚‰ä½æ‰€æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„",
            height=100,
            help="ç”»åƒã«å¯¾ã—ã¦ã©ã®ã‚ˆã†ãªåˆ†æã‚’è¡Œã„ãŸã„ã‹å…¥åŠ›ã—ã¦ãã ã•ã„"
        )

# åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
if uploaded_file and prompt and api_key:
    if st.button("ğŸ¤– AIåˆ†æã‚’å®Ÿè¡Œ", type="primary", use_container_width=True):
        with st.spinner("ç”»åƒã‚’åˆ†æä¸­..."):
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥LLM APIã«é€ä¿¡
            llm_response = call_llm_api_with_image(uploaded_file, prompt, api_key)
            
            if llm_response:
                st.session_state.llm_response = llm_response
                st.session_state.extracted_addresses = extract_addresses_from_response(llm_response)

# LLMåˆ†æçµæœã®è¡¨ç¤º
if st.session_state.llm_response:
    st.markdown("---")
    st.subheader("ğŸ¤– AIåˆ†æçµæœ")
    
    # åˆ†æçµæœã‚’è¡¨ç¤º
    with st.expander("ğŸ“‹ å®Œå…¨ãªåˆ†æçµæœ", expanded=False):
        st.markdown(st.session_state.llm_response)
    
    # æŠ½å‡ºã•ã‚ŒãŸä½æ‰€ã‚’è¡¨ç¤º
    if st.session_state.extracted_addresses:
        st.markdown("### ğŸ“ æŠ½å‡ºã•ã‚ŒãŸä½æ‰€")
        
        # ä½æ‰€ã‚’ãƒœã‚¿ãƒ³ã§è¡¨ç¤ºï¼ˆã‚¯ãƒªãƒƒã‚¯ã§ã‚«ã‚¹ã‚¿ãƒ ä½æ‰€æ¬„ã«å…¥åŠ›ï¼‰
        address_cols = st.columns(min(3, len(st.session_state.extracted_addresses)))
        for idx, address in enumerate(st.session_state.extracted_addresses):
            col_idx = idx % len(address_cols)
            with address_cols[col_idx]:
                if st.button(
                    f"ğŸ“ {address}",
                    key=f"extracted_address_{idx}",
                    use_container_width=True,
                    help="ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã‚«ã‚¹ã‚¿ãƒ ä½æ‰€æ¬„ã«å…¥åŠ›"
                ):
                    st.session_state.search_address = address
                    st.session_state.selected_extracted = address
                    st.success(f"ä½æ‰€ã‚’è¨­å®šã—ã¾ã—ãŸ: {address}")
                    st.rerun()
    
    # çµæœã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãƒœã‚¿ãƒ³
    if st.button("ğŸ—‘ï¸ åˆ†æçµæœã‚’ã‚¯ãƒªã‚¢", type="secondary"):
        st.session_state.llm_response = None
        st.session_state.extracted_addresses = []
        st.rerun()

# UIã‚³ãƒ³ãƒ†ãƒŠ
with st.container():
    st.subheader("ğŸ“ ä½æ‰€ã‚’å…¥åŠ›")
    
    # ã‚«ã‚¹ã‚¿ãƒ ä½æ‰€å…¥åŠ›
    with st.form(key='address_form'):
        col1, col2 = st.columns([4, 1])
        with col1:
            # æŠ½å‡ºã•ã‚ŒãŸä½æ‰€ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ã—ã¦è¨­å®š
            default_address = ""
            if hasattr(st.session_state, 'selected_extracted') and st.session_state.selected_extracted:
                default_address = st.session_state.selected_extracted
                # ä¸€åº¦ä½¿ã£ãŸã‚‰ã‚¯ãƒªã‚¢
                st.session_state.selected_extracted = None
            
            custom_address = st.text_input(
                "ä½æ‰€",
                value=default_address,
                placeholder="ä¾‹: æ±äº¬éƒ½åƒä»£ç”°åŒºä¸¸ã®å†…1-1-1",
                label_visibility="collapsed"
            )
        with col2:
            search_button = st.form_submit_button("ğŸ” æ¤œç´¢", type="primary", use_container_width=True)
    
    # ã‚µãƒ³ãƒ—ãƒ«ä½æ‰€é¸æŠ
    with st.expander("ğŸ’¡ ã‚µãƒ³ãƒ—ãƒ«ä½æ‰€ã‹ã‚‰é¸æŠ", expanded=False):
        sample_cols = st.columns(2)
        for idx, (address, description) in enumerate(sample_addresses.items()):
            col = sample_cols[idx % 2]
            with col:
                if st.button(f"{address}\n({description})", key=f"sample_{idx}", use_container_width=True):
                    st.session_state.search_address = address
                    st.session_state.selected_sample = address

# æ¤œç´¢å®Ÿè¡Œã®åˆ¤å®š
address = None

# ã‚«ã‚¹ã‚¿ãƒ ä½æ‰€ã®æ¤œç´¢ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆ
if search_button and custom_address:
    st.session_state.search_address = custom_address
    address = custom_address

# å‰å›ã®æ¤œç´¢çµæœã‚’ç¶­æŒã¾ãŸã¯ã‚µãƒ³ãƒ—ãƒ«é¸æŠ
elif st.session_state.search_address:
    address = st.session_state.search_address

# ä½æ‰€æƒ…å ±ã®è¡¨ç¤º
if address and address in sample_addresses:
    st.info(f"ğŸ“ {address} - {sample_addresses[address]}")

if address:
    # ä½æ‰€ã‹ã‚‰ç·¯åº¦çµŒåº¦ã‚’å–å¾—ï¼ˆå›½åœŸåœ°ç†é™¢ã‚¸ã‚ªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°APIï¼‰
    geocoding_url = f"https://msearch.gsi.go.jp/address-search/AddressSearch?q={address}"

    try:
        response = requests.get(geocoding_url)
        data = response.json()

        if data:
            # æœ€åˆã®æ¤œç´¢çµæœã‚’ä½¿ç”¨
            first_result = data[0]
            lat = first_result["geometry"]["coordinates"][1]
            lon = first_result["geometry"]["coordinates"][0]

            with st.container():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.success(f"ğŸ“ {first_result['properties']['title']}")
                with col2:
                    st.metric("åº§æ¨™", f"{lat:.4f}, {lon:.4f}", label_visibility="collapsed")

            # åœ°å›³ã‚’ä½œæˆ
            m = folium.Map(location=[lat, lon], zoom_start=15)

            # å…¥åŠ›ã—ãŸä½æ‰€ã®ä½ç½®ã«ãƒãƒ¼ã‚«ãƒ¼ã‚’é…ç½®
            folium.Marker(
                [lat, lon],
                popup=address,
                tooltip=address,
                icon=folium.Icon(color='red', icon='home')
            ).add_to(m)

            # ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚¿ã‚¤ãƒ«ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’è¿½åŠ 
            # æ´ªæ°´æµ¸æ°´æƒ³å®šåŒºåŸŸï¼ˆæƒ³å®šæœ€å¤§è¦æ¨¡ï¼‰
            folium.TileLayer(
                tiles='https://disaportaldata.gsi.go.jp/raster/01_flood_l2_shinsuishin_data/{z}/{x}/{y}.png',
                attr='å›½åœŸåœ°ç†é™¢',
                name='æ´ªæ°´æµ¸æ°´æƒ³å®šåŒºåŸŸ',
                overlay=True,
                control=True,
                opacity=0.6
            ).add_to(m)

            # æ´¥æ³¢æµ¸æ°´æƒ³å®š
            folium.TileLayer(
                tiles='https://disaportaldata.gsi.go.jp/raster/04_tsunami_newlegend_data/{z}/{x}/{y}.png',
                attr='å›½åœŸåœ°ç†é™¢',
                name='æ´¥æ³¢æµ¸æ°´æƒ³å®š',
                overlay=True,
                control=True,
                opacity=0.6
            ).add_to(m)

            # åœŸç ‚ç½å®³è­¦æˆ’åŒºåŸŸ
            folium.TileLayer(
                tiles='https://disaportaldata.gsi.go.jp/raster/05_dosekiryukeikaikuiki/{z}/{x}/{y}.png',
                attr='å›½åœŸåœ°ç†é™¢',
                name='åœŸç ‚ç½å®³è­¦æˆ’åŒºåŸŸ',
                overlay=True,
                control=True,
                opacity=0.6
            ).add_to(m)

            # ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã‚’è¿½åŠ 
            folium.LayerControl().add_to(m)

            # åœ°å›³ã¨ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—èª¬æ˜ã‚’æ¨ªä¸¦ã³ã«
            st.markdown("---")
            st.subheader("ğŸ—ºï¸ ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—")
            
            map_col, info_col = st.columns([3, 1])
            
            with map_col:
                # åœ°å›³ã‚’è¡¨ç¤º
                st_folium(m, width=700, height=500, returned_objects=[])
            
            with info_col:
                st.markdown("### å‡¡ä¾‹")
                st.markdown("""
                ğŸ”µ **æ´ªæ°´æµ¸æ°´æƒ³å®šåŒºåŸŸ**  
                æ²³å·æ°¾æ¿«æ™‚ã®æµ¸æ°´æ·±
                
                ğŸŒŠ **æ´¥æ³¢æµ¸æ°´æƒ³å®š**  
                æ´¥æ³¢ã«ã‚ˆã‚‹æµ¸æ°´æ·±
                
                ğŸŸ¡ **åœŸç ‚ç½å®³è­¦æˆ’åŒºåŸŸ**  
                åœŸç ‚ç½å®³ã®å±é™ºæ€§
                
                ---
                
                ğŸ’¡ **æ“ä½œæ–¹æ³•**
                - å³ä¸Šã®ãƒœã‚¿ãƒ³ã§ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ‡æ›¿
                - ãƒã‚¦ã‚¹ã§åœ°å›³ã®ç§»å‹•ãƒ»æ‹¡å¤§ç¸®å°
                """)
                
                st.warning("åœ°åŸŸã«ã‚ˆã£ã¦ã¯ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆãŒã‚ã‚Šã¾ã™", icon="âš ï¸")

            # å±é™ºåº¦åˆ¤å®š
            st.markdown("---")
            st.subheader("ğŸ“Š å±é™ºåº¦åˆ¤å®š")

            # å®Ÿéš›ã®ãƒã‚¶ãƒ¼ãƒ‰æƒ…å ±ã‚’å–å¾—
            hazard_info = get_hazard_info(lat, lon)
            
            # ãƒªã‚¹ã‚¯è©•ä¾¡ã‚’3åˆ—ã§è¡¨ç¤º
            risk_cols = st.columns(3)
            
            # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸè‰²ã¨ã‚¢ã‚¤ã‚³ãƒ³ã‚’è¨­å®š
            def get_risk_color(level) -> Literal["normal", "inverse", "off"]:
                if level == "é«˜ã„":
                    return "inverse"
                elif level == "ä¸­ç¨‹åº¦":
                    return "normal"
                else:
                    return "off"
            
            def get_risk_icon(level) -> str:
                if level == "é«˜ã„":
                    return "ğŸ”´"
                elif level == "ä¸­ç¨‹åº¦":
                    return "ğŸŸ¡"
                else:
                    return "ğŸŸ¢"
            
            with risk_cols[0]:
                icon = get_risk_icon(hazard_info["flood"]["level"])
                color = get_risk_color(hazard_info["flood"]["level"])
                st.metric(
                    label=f"{icon} æ´ªæ°´ãƒªã‚¹ã‚¯",
                    value=hazard_info["flood"]["level"],
                    delta=hazard_info["flood"]["detail"],
                    delta_color=color
                )
            
            with risk_cols[1]:
                icon = get_risk_icon(hazard_info["landslide"]["level"])
                color = get_risk_color(hazard_info["landslide"]["level"])
                st.metric(
                    label=f"{icon} åœŸç ‚ç½å®³ãƒªã‚¹ã‚¯",
                    value=hazard_info["landslide"]["level"],
                    delta=hazard_info["landslide"]["detail"],
                    delta_color=color
                )
            
            with risk_cols[2]:
                icon = get_risk_icon(hazard_info["tsunami"]["level"])
                color = get_risk_color(hazard_info["tsunami"]["level"])
                st.metric(
                    label=f"{icon} æ´¥æ³¢ãƒªã‚¹ã‚¯",
                    value=hazard_info["tsunami"]["level"],
                    delta=hazard_info["tsunami"]["detail"],
                    delta_color=color
                )
            
            # æ³¨æ„äº‹é …
            with st.expander("âš ï¸ é‡è¦ãªæ³¨æ„äº‹é …", expanded=False):
                st.warning("""
                - ã“ã®è©•ä¾¡ã¯æ¨™é«˜ãƒ‡ãƒ¼ã‚¿ç­‰ã‚’åŸºã«ã—ãŸç°¡æ˜“çš„ãªåˆ¤å®šã§ã™
                - æ­£ç¢ºãªæƒ…å ±ã¯å„è‡ªæ²»ä½“ã®å…¬å¼ãƒã‚¶ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã‚’ã”ç¢ºèªãã ã•ã„
                - å®Ÿéš›ã®ç½å®³ãƒªã‚¹ã‚¯ã¯åœ°å½¢ã€å»ºç‰©ã€å­£ç¯€ã€æ°—è±¡æ¡ä»¶ã«ã‚ˆã‚Šå¤‰å‹•ã—ã¾ã™
                - é¿é›£å ´æ‰€ã‚„é¿é›£çµŒè·¯ã‚‚ä½µã›ã¦ç¢ºèªã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™
                - æœ€æ–°ã®é˜²ç½æƒ…å ±ã¯è‡ªæ²»ä½“ã®é˜²ç½ãƒšãƒ¼ã‚¸ã§ã”ç¢ºèªãã ã•ã„
                """)

        else:
            st.error("ä½æ‰€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ä½æ‰€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")